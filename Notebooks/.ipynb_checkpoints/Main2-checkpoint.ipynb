{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío 3 - Grupo 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes:\n",
    "\n",
    "- Bobbio, Paula\n",
    "- Sammartino, Virginia\n",
    "- Cocio, Alex Federico\n",
    "- Onno, Olivier (?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\anaconda3\\envs\\dhdsblend\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (113) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/Aprender2018-primaria-6.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason you get this low_memory warning is because guessing dtypes for each column is very memory demanding. Pandas tries to determine what dtype to set by analyzing the data in each column. \n",
    "\n",
    "Fuente: https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ap1</th>\n",
       "      <th>ap2</th>\n",
       "      <th>ap3a</th>\n",
       "      <th>ap3b</th>\n",
       "      <th>ap3c</th>\n",
       "      <th>ap4</th>\n",
       "      <th>ap5a</th>\n",
       "      <th>ap5b</th>\n",
       "      <th>ap5c</th>\n",
       "      <th>ap5d</th>\n",
       "      <th>...</th>\n",
       "      <th>ponder</th>\n",
       "      <th>lpondera</th>\n",
       "      <th>ldesemp</th>\n",
       "      <th>lpuntaje</th>\n",
       "      <th>mpondera</th>\n",
       "      <th>mdesemp</th>\n",
       "      <th>mpuntaje</th>\n",
       "      <th>isocioa</th>\n",
       "      <th>isocioal</th>\n",
       "      <th>isocioam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227401</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1,2429398</td>\n",
       "      <td>1,2460396</td>\n",
       "      <td>3</td>\n",
       "      <td>469,66614</td>\n",
       "      <td>1,2463602</td>\n",
       "      <td>3</td>\n",
       "      <td>480,62024</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201418</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1,1717881</td>\n",
       "      <td>1,2057467</td>\n",
       "      <td>4</td>\n",
       "      <td>551,16016</td>\n",
       "      <td>1,2084954</td>\n",
       "      <td>3</td>\n",
       "      <td>562,97748</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567137</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>1,4589112</td>\n",
       "      <td>2,0456388</td>\n",
       "      <td>2</td>\n",
       "      <td>403,69412</td>\n",
       "      <td>1,8735921</td>\n",
       "      <td>1</td>\n",
       "      <td>316,00403</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157593</th>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1,1022998</td>\n",
       "      <td>1,1029279</td>\n",
       "      <td>1</td>\n",
       "      <td>363,22083</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396477</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1,1017737</td>\n",
       "      <td>1,0994167</td>\n",
       "      <td>3</td>\n",
       "      <td>467,85693</td>\n",
       "      <td>1,0984224</td>\n",
       "      <td>1</td>\n",
       "      <td>340,57278</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ap1  ap2  ap3a  ap3b  ap3c  ap4  ap5a  ap5b  ap5c  ap5d  ...  \\\n",
       "227401    2    2     1     9     9    5     1     2     1     2  ...   \n",
       "201418    4    1     1     1     1    4     1    -9     2     1  ...   \n",
       "567137    2    2     1     1     1    3     1    -9    -9    -9  ...   \n",
       "157593    3   -9     1     1     1    6     1     1    -9     1  ...   \n",
       "396477    2    1     1    -9    -9    6     1     2    -9     1  ...   \n",
       "\n",
       "           ponder   lpondera  ldesemp   lpuntaje   mpondera  mdesemp  \\\n",
       "227401  1,2429398  1,2460396        3  469,66614  1,2463602        3   \n",
       "201418  1,1717881  1,2057467        4  551,16016  1,2084954        3   \n",
       "567137  1,4589112  2,0456388        2  403,69412  1,8735921        1   \n",
       "157593  1,1022998  1,1029279        1  363,22083                       \n",
       "396477  1,1017737  1,0994167        3  467,85693  1,0984224        1   \n",
       "\n",
       "         mpuntaje  isocioa  isocioal  isocioam  \n",
       "227401  480,62024       -1        -1        -1  \n",
       "201418  562,97748        1         1         1  \n",
       "567137  316,00403        2         2         2  \n",
       "157593                   2         2            \n",
       "396477  340,57278        2         2         2  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descartamos manualmente las variables que consideramos redundantes para el problema. Estas son:\n",
    "- Indice del Contexto Social de la Educación\n",
    "- Factor de expansión (solo para variable cuestionario complementario)\n",
    "- Factor de expansión prueba de Lengua\n",
    "- Puntaje en Lengua\n",
    "- Factor de expansión prueba de Matemática\n",
    "- Puntaje en Matemática\n",
    "- Indice socioeconómico del alumno\n",
    "- Indice socioeconómico del alumno ponderador Lengua\n",
    "- Indice socioeconómico del alumno ponderador Matemática\n",
    "\n",
    "- Desempeño en Lengua\n",
    "\n",
    "**¿Deberíamos explicar por qué?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminamos 10 columnas.\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['ICSE','ponder','lpondera','lpuntaje','mpondera','mpuntaje','isocioa','isocioal','isocioam', 'ldesemp']\n",
    "data1 = data.drop(columns_to_drop, axis=1)\n",
    "print('Eliminamos', data.shape[1]-data1.shape[1], 'columnas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizamos algunas características del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 579510 entries, 0 to 579509\n",
      "Columns: 114 entries, ap1 to mdesemp\n",
      "dtypes: int64(113), object(1)\n",
      "memory usage: 504.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# ¿Cuántas observaciones hay en la tabla?\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset tiene 579510 filas y 114 columnas.\n"
     ]
    }
   ],
   "source": [
    "# Dimensión del dataframe\n",
    "print('El dataset tiene', data1.shape[0], 'filas y', data1.shape[1], 'columnas.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     113\n",
       "object      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Qué tipo de datos tiene?\n",
    "data1.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos faltantes: 0\n"
     ]
    }
   ],
   "source": [
    "# ¿Hay datos faltantes?\n",
    "print('Datos faltantes:', data1.isnull().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.37\n",
       "2    0.21\n",
       "4    0.20\n",
       "1    0.18\n",
       "     0.05\n",
       "Name: mdesemp, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Están balanceados los datos de la variable target?\n",
    "data1.mdesemp.value_counts(normalize=True, ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.countplot(data1.mdesemp.sort_values(), label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunas consideraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Elimino las filas que no especifica ningún valor en la columna target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ap1</th>\n",
       "      <th>ap2</th>\n",
       "      <th>ap3a</th>\n",
       "      <th>ap3b</th>\n",
       "      <th>ap3c</th>\n",
       "      <th>ap4</th>\n",
       "      <th>ap5a</th>\n",
       "      <th>ap5b</th>\n",
       "      <th>ap5c</th>\n",
       "      <th>ap5d</th>\n",
       "      <th>...</th>\n",
       "      <th>ap39</th>\n",
       "      <th>ap40</th>\n",
       "      <th>ap41a</th>\n",
       "      <th>ap41b</th>\n",
       "      <th>ap41c</th>\n",
       "      <th>ap42</th>\n",
       "      <th>cod_provincia</th>\n",
       "      <th>sector</th>\n",
       "      <th>ambito</th>\n",
       "      <th>mdesemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579431</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579432</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579483</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-6</td>\n",
       "      <td>-1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579493</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579494</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27479 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ap1  ap2  ap3a  ap3b  ap3c  ap4  ap5a  ap5b  ap5c  ap5d  ...  ap39  \\\n",
       "11        3    1     1     1     1    3     2     2    -9    -9  ...    -1   \n",
       "45        2    1     1     1     1    7     1     2     2     2  ...    -1   \n",
       "61        2    1     1     2     2    4     1     1    -9     1  ...    -1   \n",
       "62        3    1     1     1     1    4     1     1     2     1  ...    -1   \n",
       "63        2    1     1     1     1    6     1     2     2     1  ...    -1   \n",
       "...     ...  ...   ...   ...   ...  ...   ...   ...   ...   ...  ...   ...   \n",
       "579431    2    2     1     1     1    3     1     1     2     1  ...    -1   \n",
       "579432    2    2     1     1     1    3     1     2     2     2  ...    -1   \n",
       "579483    3    2     1     1     1    5     1     1     2     2  ...    -1   \n",
       "579493    2    2     8     8     8    4     1     1    -9    -9  ...    -1   \n",
       "579494    2    1     1     8     8    5     1     2     2    -6  ...    -1   \n",
       "\n",
       "        ap40  ap41a  ap41b  ap41c  ap42  cod_provincia  sector  ambito  \\\n",
       "11        -1      1      1     -9    -1              6       1       1   \n",
       "45        -1      2      2     -9    -1              6       1       1   \n",
       "61        -1      2      2      1    -1              6       1       1   \n",
       "62        -1      2      3      1    -1              6       1       1   \n",
       "63        -1     -9     -9     -9    -1              6       1       1   \n",
       "...      ...    ...    ...    ...   ...            ...     ...     ...   \n",
       "579431    -1      2      3      1    -1             94       1       1   \n",
       "579432    -1      2      4      2    -1             94       1       1   \n",
       "579483    -1      1     -9     -6    -1             94       1       1   \n",
       "579493    -1     -9     -9     -9    -1             94       1       1   \n",
       "579494    -1      2      2      2    -1             94       1       1   \n",
       "\n",
       "        mdesemp  \n",
       "11               \n",
       "45               \n",
       "61               \n",
       "62               \n",
       "63               \n",
       "...         ...  \n",
       "579431           \n",
       "579432           \n",
       "579483           \n",
       "579493           \n",
       "579494           \n",
       "\n",
       "[27479 rows x 114 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_mask = data1.mdesemp == ' '\n",
    "data1.loc[empty_mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = data1[empty_mask].index\n",
    "data2 = data1.drop(indexNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    0.38\n",
      "2    0.23\n",
      "4    0.21\n",
      "1    0.19\n",
      "Name: mdesemp, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data2.mdesemp.value_counts(normalize=True, ascending=False).round(2))\n",
    "\n",
    "sns.countplot(data2.mdesemp.sort_values(), label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Podría mejorar el gráfico (agregando labels adentro de la figura que indiquen las proporciones de cada barra)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_rename = data2.rename(columns={'ap1': 'edad', 'ap2':'sexo', 'ap4':'personasconv', 'ap7a':'internet' ,\n",
    "                            'ap7b':'agua', 'ap7c':'compu', 'ap9':'educmam', 'ap14':'trabajofam', 'ap15':'trabajofuera',\n",
    "                            'ap16':'jardin' , 'ap17':'repetidor', 'ap22':'opmat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Creamos una muestra para agilizar el tiempo computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos a trabajar con una muestra del 0.0 % del dataset.\n"
     ]
    }
   ],
   "source": [
    "data2_sample = data2_rename.sample(frac=0.001, random_state=2)\n",
    "print('Vamos a trabajar con una muestra del', round(data2_sample.shape[0]/data2.shape[0],1)*100,'% del dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552, 114)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    0.40\n",
      "4    0.22\n",
      "2    0.19\n",
      "1    0.18\n",
      "Name: mdesemp, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data2_sample.mdesemp.value_counts(normalize=True, ascending=False).round(2))\n",
    "\n",
    "sns.countplot(data2_sample.mdesemp.sort_values(), label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# pasos = [('sample', df_new.sample(frac=0.5, random_state=2), , ('estandarizar', OneHotEncoder(), 'modelos', KNeighborsClassifier))]\n",
    "# pipe = Pipeline(pasos)\n",
    "# pipe.steps[0]\n",
    "# pipe.steps[1]\n",
    "# pipe.steps[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armamos la matriz de predictores ($X$) (vamos a seleccionar sólo algunas columnas) y el target ($y$) (que es el nivel de desempeño en Matemática)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols=['edad', 'sexo', 'personasconv', 'internet', 'agua', 'compu', 'educmam', 'trabajofam', 'trabajofuera', 'jardin', 'repetidor', 'opmat']\n",
    "X = data2_sample[cols]\n",
    "y = data2_sample['mdesemp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombramos el nombre de las columnas con un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un diccionario para reemplazar el nombre de las columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos fijamos la distribución de las etiquetas para evaluar si hay un desbalanceo en las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.400362\n",
       "4    0.221014\n",
       "2    0.193841\n",
       "1    0.184783\n",
       "Name: mdesemp, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponiendo que están relativamente balanceadas, continuamos... **(caso contrario, ¿cómo balanceo? ¿transformando las 4 clases en 2?)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el split entre train y test (y por las dudas usamos el argumento de **stratify** para mantener la proporción de los niveles en los datos de train y test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(111, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(441,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(111,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=56)\n",
    "display(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Hace falta estandarizar en este caso? Los features están en las mismas unidades pero las escalas podrían ser distintas\n",
    "\n",
    "The type of encoding used here is called \"label encoding\" - and it is very simple: we just assign an ID for a categorical value.\n",
    "\n",
    "Our computer now knows how to represent these categories, because it knows how to work with numbers. However, this method of encoding is not very effective, because it tends to naturally give the higher numbers higher weights.\n",
    "\n",
    "It wouldn't make sense to say that our category of \"Argentina\" is greater or smaller than \"Paraguay\", or that adding the category \"Lemon\" to \"Peach\" would give us a category \"Orange\", since these values are not ordinal.\n",
    "\n",
    "If we represented these categories in one-hot encoding, we would actually replace the rows with columns. We do this by creating one boolean column for each of our given categories, where only one of these columns could take on the value 1 for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>-9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2    3    4    5    1   -9\n",
       "0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "1  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "3  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "# fiteo y transformo la columna \"edad\"\n",
    "dummy_oneHot = onehot_encoder.fit_transform(data2_sample[['edad']])\n",
    "# pongo un vector en un dataset.\n",
    "dummy_oneHot = pd.DataFrame(dummy_oneHot.toarray(),columns=data2_sample['edad'].unique())\n",
    "dummy_oneHot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la codificación **\"One-Hot-Enconding\" induce una multicolinealidad perfecta**, eliminamos una de las columnas de las características codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4\n",
       "0  0.0  1.0  0.0  0.0  0.0\n",
       "1  0.0  1.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  1.0  0.0  0.0\n",
       "3  0.0  1.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  1.0  0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder2 = OneHotEncoder(drop='first')\n",
    "# fiteo y transformo la columna \"edad\"\n",
    "dummy_oneHot_correct = onehot_encoder2.fit_transform(data2_sample[['edad']])\n",
    "# pongo un vector en un dataset.\n",
    "dummy_oneHot_correct = pd.DataFrame(dummy_oneHot_correct.toarray())\n",
    "dummy_oneHot_correct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estandarizar_feature(a):\n",
    "    onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    # fiteo y transformo la columna \"nombre_de_feature\"\n",
    "    dummy_oneHot = onehot_encoder.fit_transform(data2_sample[[a]])\n",
    "    # pongo un vector en un dataset.\n",
    "    dummy_oneHot = pd.DataFrame(dummy_oneHot.toarray(),columns=data2_sample[a].unique())\n",
    "    # elimino la multicolinealidad perfecta\n",
    "    onehot_encoder2 = OneHotEncoder(drop='first')\n",
    "    # fiteo y transformo la columna \"nombre_de_feature\"\n",
    "    dummy_oneHot_correct = onehot_encoder2.fit_transform(data2_sample[[a]])\n",
    "    # pongo un vector en un dataset.\n",
    "    dummy_oneHot_correct = pd.DataFrame(dummy_oneHot_correct.toarray())\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "estandarizar_feature('sexo')\n",
    "estandarizar_feature('personasconv')\n",
    "estandarizar_feature('internet')\n",
    "estandarizar_feature('agua')\n",
    "estandarizar_feature('compu')\n",
    "estandarizar_feature('educmam')\n",
    "estandarizar_feature('trabajofam')\n",
    "estandarizar_feature('trabajofuera')\n",
    "estandarizar_feature('jardin')\n",
    "estandarizar_feature('repetidor')\n",
    "estandarizar_feature('opmat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos la variables \"mdesemp\" para generar una variable derivada que tenga en cuenta que es mejor si el desempeño es \"satsifactorio\". Con esto podemos generar por ejemplo una variable categórica que puede ser utilizada como vector \"objetivo\" en un problema de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(data2_sample['mdesemp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora usar GRIDSEARCH CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos primero importando el método de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos el estimador/modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la grilla de parámetros que queremos testear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la cantidad de folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=10, random_state=19, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos el método `GridSearchCV` eligiendo **accuracy** como medida de scoring dado que los datos están **balanceados**, y el resto de argumentos que definimos arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_grid, cv=folds, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos utilizando el método .fit de grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=19, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSeachCV` devuelve un dict con mucha información. Desde el tiempo de fiteo de cada parámetro hasta los scores promedio (vía validación cruzada). También provee los score en cada train y test set de la K-Fold Cross Validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_n_neighbors', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cv_results_ podemos ver los detalles de cada uno de los hierparámetros o combinación de hiperparámeros que evaluó el GridSeachCV. Incluso podemos ver el score obtenido en cada split, el mean_test_score y el std_test_score.\n",
    "\n",
    "Además, encontramos el rank_test_score que nos indica cuál fue el hiperparámetro o combinación de hiperparámetros que obtuvo el mejor score de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.009946</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.369747</td>\n",
       "      <td>0.063318</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017185</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.019033</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.294747</td>\n",
       "      <td>0.043991</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009893</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.312879</td>\n",
       "      <td>0.043658</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019874</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.340202</td>\n",
       "      <td>0.066147</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.015179</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.349192</td>\n",
       "      <td>0.060168</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014223</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333232</td>\n",
       "      <td>0.047938</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014092</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.365051</td>\n",
       "      <td>0.081422</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015161</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.355960</td>\n",
       "      <td>0.063166</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013662</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.016583</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.355960</td>\n",
       "      <td>0.079787</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015126</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.367323</td>\n",
       "      <td>0.057999</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018142</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.365101</td>\n",
       "      <td>0.058865</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.018373</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>12</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.365101</td>\n",
       "      <td>0.055244</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.020017</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.381010</td>\n",
       "      <td>0.062771</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.019670</td>\n",
       "      <td>0.004265</td>\n",
       "      <td>0.026384</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>14</td>\n",
       "      <td>{'n_neighbors': 14}</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.383182</td>\n",
       "      <td>0.030630</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.017132</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.020105</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.044459</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.018009</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.022334</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.372020</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.016904</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>18</td>\n",
       "      <td>{'n_neighbors': 18}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.367323</td>\n",
       "      <td>0.029741</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.014352</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.374141</td>\n",
       "      <td>0.042061</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.014609</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.376515</td>\n",
       "      <td>0.037735</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.008450</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.371919</td>\n",
       "      <td>0.039885</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.017698</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.018144</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>22</td>\n",
       "      <td>{'n_neighbors': 22}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.376515</td>\n",
       "      <td>0.039079</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.015878</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>0.019576</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>23</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.374192</td>\n",
       "      <td>0.037324</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.012285</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>24</td>\n",
       "      <td>{'n_neighbors': 24}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.378737</td>\n",
       "      <td>0.048057</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>25</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.383283</td>\n",
       "      <td>0.036402</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.016086</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.023281</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>26</td>\n",
       "      <td>{'n_neighbors': 26}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.390101</td>\n",
       "      <td>0.035622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.019233</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.022534</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>27</td>\n",
       "      <td>{'n_neighbors': 27}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.032461</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.017518</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.021851</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>28</td>\n",
       "      <td>{'n_neighbors': 28}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.030717</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.019308</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.023510</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_neighbors': 29}</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.392273</td>\n",
       "      <td>0.039157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.022047</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_neighbors': 30}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.381061</td>\n",
       "      <td>0.031245</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.008308      0.001644         0.009946        0.003243   \n",
       "1        0.017185      0.007026         0.019033        0.006916   \n",
       "2        0.009893      0.003659         0.015068        0.006614   \n",
       "3        0.019874      0.009805         0.021681        0.007773   \n",
       "4        0.016361      0.007353         0.015179        0.004703   \n",
       "5        0.014223      0.004510         0.016773        0.007228   \n",
       "6        0.014092      0.003924         0.014846        0.004086   \n",
       "7        0.015161      0.005426         0.015609        0.004496   \n",
       "8        0.013662      0.005860         0.016583        0.006026   \n",
       "9        0.015126      0.004089         0.020157        0.005618   \n",
       "10       0.018142      0.003561         0.023529        0.003019   \n",
       "11       0.018373      0.001457         0.020576        0.003121   \n",
       "12       0.020017      0.004012         0.020344        0.003330   \n",
       "13       0.019670      0.004265         0.026384        0.008231   \n",
       "14       0.017132      0.002822         0.022140        0.002842   \n",
       "15       0.020105      0.003526         0.027559        0.006647   \n",
       "16       0.018009      0.003376         0.022334        0.002755   \n",
       "17       0.016904      0.008130         0.018060        0.006933   \n",
       "18       0.014352      0.004249         0.017268        0.003280   \n",
       "19       0.014609      0.005103         0.014891        0.003715   \n",
       "20       0.008450      0.002575         0.010861        0.002591   \n",
       "21       0.017698      0.004144         0.018144        0.004229   \n",
       "22       0.015878      0.005342         0.019576        0.007305   \n",
       "23       0.012285      0.004147         0.013009        0.005579   \n",
       "24       0.018470      0.003644         0.027127        0.007153   \n",
       "25       0.016086      0.002766         0.023281        0.003088   \n",
       "26       0.019233      0.004311         0.022534        0.004255   \n",
       "27       0.017518      0.002586         0.021851        0.002838   \n",
       "28       0.019308      0.004643         0.023510        0.004271   \n",
       "29       0.022047      0.009308         0.024752        0.009775   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_score  \\\n",
       "0                  1   {'n_neighbors': 1}           0.311111   \n",
       "1                  2   {'n_neighbors': 2}           0.311111   \n",
       "2                  3   {'n_neighbors': 3}           0.333333   \n",
       "3                  4   {'n_neighbors': 4}           0.311111   \n",
       "4                  5   {'n_neighbors': 5}           0.355556   \n",
       "5                  6   {'n_neighbors': 6}           0.377778   \n",
       "6                  7   {'n_neighbors': 7}           0.377778   \n",
       "7                  8   {'n_neighbors': 8}           0.377778   \n",
       "8                  9   {'n_neighbors': 9}           0.377778   \n",
       "9                 10  {'n_neighbors': 10}           0.377778   \n",
       "10                11  {'n_neighbors': 11}           0.355556   \n",
       "11                12  {'n_neighbors': 12}           0.355556   \n",
       "12                13  {'n_neighbors': 13}           0.355556   \n",
       "13                14  {'n_neighbors': 14}           0.400000   \n",
       "14                15  {'n_neighbors': 15}           0.333333   \n",
       "15                16  {'n_neighbors': 16}           0.333333   \n",
       "16                17  {'n_neighbors': 17}           0.311111   \n",
       "17                18  {'n_neighbors': 18}           0.377778   \n",
       "18                19  {'n_neighbors': 19}           0.377778   \n",
       "19                20  {'n_neighbors': 20}           0.333333   \n",
       "20                21  {'n_neighbors': 21}           0.355556   \n",
       "21                22  {'n_neighbors': 22}           0.333333   \n",
       "22                23  {'n_neighbors': 23}           0.355556   \n",
       "23                24  {'n_neighbors': 24}           0.355556   \n",
       "24                25  {'n_neighbors': 25}           0.355556   \n",
       "25                26  {'n_neighbors': 26}           0.355556   \n",
       "26                27  {'n_neighbors': 27}           0.333333   \n",
       "27                28  {'n_neighbors': 28}           0.333333   \n",
       "28                29  {'n_neighbors': 29}           0.400000   \n",
       "29                30  {'n_neighbors': 30}           0.333333   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.409091           0.522727           0.340909   \n",
       "1            0.272727           0.386364           0.318182   \n",
       "2            0.340909           0.386364           0.272727   \n",
       "3            0.272727           0.477273           0.363636   \n",
       "4            0.295455           0.477273           0.272727   \n",
       "5            0.295455           0.340909           0.272727   \n",
       "6            0.386364           0.500000           0.227273   \n",
       "7            0.318182           0.454545           0.272727   \n",
       "8            0.318182           0.477273           0.250000   \n",
       "9            0.409091           0.386364           0.340909   \n",
       "10           0.318182           0.386364           0.250000   \n",
       "11           0.363636           0.409091           0.318182   \n",
       "12           0.386364           0.409091           0.318182   \n",
       "13           0.386364           0.386364           0.318182   \n",
       "14           0.386364           0.340909           0.318182   \n",
       "15           0.386364           0.409091           0.340909   \n",
       "16           0.386364           0.409091           0.318182   \n",
       "17           0.386364           0.431818           0.318182   \n",
       "18           0.386364           0.454545           0.340909   \n",
       "19           0.386364           0.454545           0.318182   \n",
       "20           0.386364           0.454545           0.318182   \n",
       "21           0.409091           0.386364           0.318182   \n",
       "22           0.409091           0.431818           0.340909   \n",
       "23           0.386364           0.500000           0.340909   \n",
       "24           0.386364           0.454545           0.340909   \n",
       "25           0.386364           0.454545           0.340909   \n",
       "26           0.409091           0.454545           0.340909   \n",
       "27           0.386364           0.431818           0.340909   \n",
       "28           0.386364           0.477273           0.318182   \n",
       "29           0.363636           0.386364           0.340909   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.295455           0.386364           0.340909   \n",
       "1            0.272727           0.318182           0.295455   \n",
       "2            0.318182           0.363636           0.250000   \n",
       "3            0.295455           0.409091           0.295455   \n",
       "4            0.318182           0.363636           0.340909   \n",
       "5            0.295455           0.431818           0.318182   \n",
       "6            0.295455           0.454545           0.295455   \n",
       "7            0.318182           0.431818           0.250000   \n",
       "8            0.318182           0.500000           0.250000   \n",
       "9            0.295455           0.477273           0.272727   \n",
       "10           0.363636           0.454545           0.318182   \n",
       "11           0.295455           0.500000           0.340909   \n",
       "12           0.340909           0.522727           0.409091   \n",
       "13           0.386364           0.431818           0.386364   \n",
       "14           0.431818           0.431818           0.363636   \n",
       "15           0.431818           0.454545           0.363636   \n",
       "16           0.386364           0.431818           0.386364   \n",
       "17           0.340909           0.363636           0.363636   \n",
       "18           0.363636           0.409091           0.363636   \n",
       "19           0.363636           0.409091           0.386364   \n",
       "20           0.363636           0.431818           0.363636   \n",
       "21           0.409091           0.454545           0.340909   \n",
       "22           0.431818           0.363636           0.340909   \n",
       "23           0.386364           0.409091           0.340909   \n",
       "24           0.409091           0.409091           0.386364   \n",
       "25           0.409091           0.431818           0.386364   \n",
       "26           0.386364           0.409091           0.386364   \n",
       "27           0.409091           0.409091           0.386364   \n",
       "28           0.409091           0.409091           0.363636   \n",
       "29           0.409091           0.409091           0.431818   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.363636           0.318182           0.409091         0.369747   \n",
       "1            0.295455           0.272727           0.204545         0.294747   \n",
       "2            0.295455           0.250000           0.318182         0.312879   \n",
       "3            0.386364           0.340909           0.250000         0.340202   \n",
       "4            0.431818           0.340909           0.295455         0.349192   \n",
       "5            0.386364           0.318182           0.295455         0.333232   \n",
       "6            0.454545           0.340909           0.318182         0.365051   \n",
       "7            0.363636           0.363636           0.409091         0.355960   \n",
       "8            0.386364           0.363636           0.318182         0.355960   \n",
       "9            0.409091           0.386364           0.318182         0.367323   \n",
       "10           0.454545           0.386364           0.363636         0.365101   \n",
       "11           0.386364           0.363636           0.318182         0.365101   \n",
       "12           0.431818           0.295455           0.340909         0.381010   \n",
       "13           0.409091           0.340909           0.386364         0.383182   \n",
       "14           0.431818           0.363636           0.386364         0.378788   \n",
       "15           0.431818           0.318182           0.363636         0.383333   \n",
       "16           0.409091           0.363636           0.318182         0.372020   \n",
       "17           0.386364           0.340909           0.363636         0.367323   \n",
       "18           0.409091           0.295455           0.340909         0.374141   \n",
       "19           0.386364           0.340909           0.386364         0.376515   \n",
       "20           0.363636           0.340909           0.340909         0.371919   \n",
       "21           0.363636           0.363636           0.386364         0.376515   \n",
       "22           0.386364           0.318182           0.363636         0.374192   \n",
       "23           0.386364           0.318182           0.363636         0.378737   \n",
       "24           0.409091           0.340909           0.340909         0.383283   \n",
       "25           0.386364           0.340909           0.409091         0.390101   \n",
       "26           0.386364           0.386364           0.386364         0.387879   \n",
       "27           0.409091           0.363636           0.363636         0.383333   \n",
       "28           0.386364           0.409091           0.363636         0.392273   \n",
       "29           0.409091           0.363636           0.363636         0.381061   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.063318               18  \n",
       "1         0.043991               30  \n",
       "2         0.043658               29  \n",
       "3         0.066147               27  \n",
       "4         0.060168               26  \n",
       "5         0.047938               28  \n",
       "6         0.081422               23  \n",
       "7         0.063166               24  \n",
       "8         0.079787               24  \n",
       "9         0.057999               19  \n",
       "10        0.058865               22  \n",
       "11        0.055244               21  \n",
       "12        0.062771                9  \n",
       "13        0.030630                7  \n",
       "14        0.040230               10  \n",
       "15        0.044459                5  \n",
       "16        0.040643               16  \n",
       "17        0.029741               20  \n",
       "18        0.042061               15  \n",
       "19        0.037735               13  \n",
       "20        0.039885               17  \n",
       "21        0.039079               12  \n",
       "22        0.037324               14  \n",
       "23        0.048057               11  \n",
       "24        0.036402                6  \n",
       "25        0.035622                2  \n",
       "26        0.032461                3  \n",
       "27        0.030717                4  \n",
       "28        0.039157                1  \n",
       "29        0.031245                8  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también acceder rápidamente a cuál fue el mejor modelo (ya que cuando tengamos muchos hiperparámetros no va a ser demasiado práctico ver la información de cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=29)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver todos los hiperparámetros del mejor modelo, donde se observa que el número óptimo de vecinos es 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39227272727272733"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_score_ nos indica cuál fue la performance promedio del score de validación del grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 29}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finalmente best_params_ nos muestra cuáles fueron los hiperparámetros seleccionados luego de la búsqueda exhaustiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UN HIPERMPARÁMETRO MÁS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a agregar el parámetro binario de Peso del algoritmo KNN que determina si algunos vecinos tendrán mayor ponderación que otros a la hora de clasificar. El valor distance indica que el peso es inversamente proporcional a la distancia.\n",
    "\n",
    "GridSearchCV exige que la grilla de parámetros a explorar venga en un diccionario con los nombres de los parámetros y la lista de los posibles valores.\n",
    "\n",
    "Noten que GridSearchCV tiene todos los métodos que la API de sklearn ofrece para modelos predictivos: fit, predict, predict_proba, etc. Es decir que una vez que tenemos el mejor modelo, podemos directamente usar el método predict de GridSearchCV. Algo que hace GridSearchCV es que una vez que elije el mejor o la mejor combinación de hiperparémetros, re-entrena el estimador o modelo utilizando esa combinación de hiperparámetros pero usando ahora todos los datos de train. Esto nos ahorra tener que entrenar nuevamente el modelo, y nos permite ir directamente a testearlo con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ahora el tunning se realizará iterando y alternando weights y k (nro. de vecinos cercanos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos nuevamente el modelo como hicimos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=19, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(knn, param_grid, cv=folds, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011163</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 1, 'weights': 'uniform'}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.369747</td>\n",
       "      <td>0.063318</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 1, 'weights': 'distance'}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.369747</td>\n",
       "      <td>0.063318</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.005597</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.294747</td>\n",
       "      <td>0.043991</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011975</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.009983</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'distance'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.326465</td>\n",
       "      <td>0.048413</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011830</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'uniform'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.312879</td>\n",
       "      <td>0.043658</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.344596</td>\n",
       "      <td>0.049984</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016490</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'uniform'}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.340202</td>\n",
       "      <td>0.066147</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'distance'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.346970</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010644</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.012904</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.349192</td>\n",
       "      <td>0.060168</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014265</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.349192</td>\n",
       "      <td>0.045504</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011697</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.015780</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333232</td>\n",
       "      <td>0.047938</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.326566</td>\n",
       "      <td>0.037162</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015036</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.019912</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.365051</td>\n",
       "      <td>0.081422</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.015534</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'distance'}</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.374091</td>\n",
       "      <td>0.059891</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.014582</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.016221</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 8, 'weights': 'uniform'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.355960</td>\n",
       "      <td>0.063166</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.017961</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.015995</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>8</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 8, 'weights': 'distance'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.358283</td>\n",
       "      <td>0.050602</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'uniform'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.355960</td>\n",
       "      <td>0.079787</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'distance'}</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.380859</td>\n",
       "      <td>0.052766</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.017275</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'uniform'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.367323</td>\n",
       "      <td>0.057999</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.015101</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'distance'}</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.380859</td>\n",
       "      <td>0.047620</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.023492</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>11</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.365101</td>\n",
       "      <td>0.058865</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.018040</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>11</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'distance'}</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.376364</td>\n",
       "      <td>0.038985</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>12</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 12, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.365101</td>\n",
       "      <td>0.055244</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.017873</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>12</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 12, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.385505</td>\n",
       "      <td>0.035303</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.018701</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.023144</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>13</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 13, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.381010</td>\n",
       "      <td>0.062771</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.017414</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.015422</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>13</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 13, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.383232</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.019991</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>14</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 14, 'weights': 'uniform'}</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.383182</td>\n",
       "      <td>0.030630</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.021409</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.017302</td>\n",
       "      <td>0.004370</td>\n",
       "      <td>14</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 14, 'weights': 'distance'}</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.394545</td>\n",
       "      <td>0.040696</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.012616</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>15</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 15, 'weights': 'uniform'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>15</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 15, 'weights': 'distance'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.017634</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>16</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 16, 'weights': 'uniform'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.044459</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.019202</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.015643</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>16</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 16, 'weights': 'distance'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.394697</td>\n",
       "      <td>0.040719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.019760</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.021303</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>17</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 17, 'weights': 'uniform'}</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.372020</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.020869</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>17</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 17, 'weights': 'distance'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.378737</td>\n",
       "      <td>0.049120</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.020579</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>18</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 18, 'weights': 'uniform'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.367323</td>\n",
       "      <td>0.029741</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>18</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 18, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.371869</td>\n",
       "      <td>0.044347</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.017284</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.022218</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>19</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 19, 'weights': 'uniform'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.374141</td>\n",
       "      <td>0.042061</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.019692</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.014625</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 19, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.378687</td>\n",
       "      <td>0.051827</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'uniform'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.376515</td>\n",
       "      <td>0.037735</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.011135</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.390051</td>\n",
       "      <td>0.035120</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.021754</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>21</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 21, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.371919</td>\n",
       "      <td>0.039885</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>21</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 21, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387778</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.018475</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.022013</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>22</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 22, 'weights': 'uniform'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.376515</td>\n",
       "      <td>0.039079</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>22</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 22, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.392323</td>\n",
       "      <td>0.039662</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.019205</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>23</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 23, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.374192</td>\n",
       "      <td>0.037324</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.019661</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>23</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 23, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.383232</td>\n",
       "      <td>0.043689</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.024041</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>24</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 24, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.378737</td>\n",
       "      <td>0.048057</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.019506</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>24</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 24, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.378687</td>\n",
       "      <td>0.043123</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.022621</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.026314</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>25</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 25, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.383283</td>\n",
       "      <td>0.036402</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>25</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 25, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.392323</td>\n",
       "      <td>0.045712</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>26</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 26, 'weights': 'uniform'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.390101</td>\n",
       "      <td>0.035622</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.015307</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>26</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 26, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.387778</td>\n",
       "      <td>0.052373</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>27</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 27, 'weights': 'uniform'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.032461</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.018922</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>27</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 27, 'weights': 'distance'}</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.392323</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.018960</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.021511</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>28</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 28, 'weights': 'uniform'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.030717</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.021237</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.017230</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>28</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 28, 'weights': 'distance'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.042412</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.017987</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.023696</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>29</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 29, 'weights': 'uniform'}</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.392273</td>\n",
       "      <td>0.039157</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.018260</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>29</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 29, 'weights': 'distance'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.390101</td>\n",
       "      <td>0.042255</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.023520</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 30, 'weights': 'uniform'}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.381061</td>\n",
       "      <td>0.031245</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.019445</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.014546</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>30</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 30, 'weights': 'distance'}</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.387828</td>\n",
       "      <td>0.035059</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.011163      0.001762         0.012080        0.004624   \n",
       "1        0.022312      0.004839         0.018218        0.005476   \n",
       "2        0.013738      0.006599         0.016634        0.005597   \n",
       "3        0.011975      0.002891         0.009983        0.004640   \n",
       "4        0.011830      0.002506         0.012499        0.003204   \n",
       "5        0.012557      0.004860         0.011066        0.003996   \n",
       "6        0.016490      0.007069         0.013720        0.002373   \n",
       "7        0.014775      0.004466         0.011716        0.003399   \n",
       "8        0.010644      0.005196         0.012904        0.003832   \n",
       "9        0.014265      0.004958         0.011464        0.003145   \n",
       "10       0.011697      0.003516         0.015780        0.007203   \n",
       "11       0.015604      0.005108         0.013441        0.003470   \n",
       "12       0.015036      0.002678         0.019912        0.005176   \n",
       "13       0.015534      0.004765         0.011639        0.002655   \n",
       "14       0.014582      0.003901         0.016221        0.003424   \n",
       "15       0.017961      0.005358         0.015995        0.008677   \n",
       "16       0.015038      0.004910         0.018028        0.006305   \n",
       "17       0.010821      0.002650         0.008837        0.004134   \n",
       "18       0.013811      0.004687         0.017275        0.005272   \n",
       "19       0.019982      0.005383         0.015101        0.002648   \n",
       "20       0.015923      0.003496         0.023492        0.003486   \n",
       "21       0.018040      0.002507         0.014835        0.002745   \n",
       "22       0.020099      0.006721         0.024256        0.005136   \n",
       "23       0.017873      0.002432         0.015087        0.002588   \n",
       "24       0.018701      0.003871         0.023144        0.003418   \n",
       "25       0.017414      0.004227         0.015422        0.002764   \n",
       "26       0.018042      0.002975         0.019991        0.003482   \n",
       "27       0.021409      0.005584         0.017302        0.004370   \n",
       "28       0.012616      0.004602         0.015610        0.006299   \n",
       "29       0.017172      0.003185         0.016318        0.002380   \n",
       "30       0.017634      0.002421         0.023581        0.003328   \n",
       "31       0.019202      0.003522         0.015643        0.003406   \n",
       "32       0.019760      0.001544         0.021303        0.003942   \n",
       "33       0.020869      0.004427         0.018010        0.004248   \n",
       "34       0.018198      0.004045         0.020579        0.003437   \n",
       "35       0.019604      0.004927         0.015529        0.002887   \n",
       "36       0.017284      0.004406         0.022218        0.004012   \n",
       "37       0.019692      0.002531         0.014625        0.003044   \n",
       "38       0.011526      0.006842         0.015072        0.011036   \n",
       "39       0.011135      0.003281         0.008457        0.002522   \n",
       "40       0.015902      0.003474         0.021754        0.003393   \n",
       "41       0.018456      0.003673         0.016548        0.001963   \n",
       "42       0.018475      0.004618         0.022013        0.003274   \n",
       "43       0.016742      0.002942         0.015986        0.002060   \n",
       "44       0.019205      0.006255         0.026215        0.003828   \n",
       "45       0.019661      0.002481         0.014160        0.003011   \n",
       "46       0.024041      0.004254         0.025920        0.005293   \n",
       "47       0.019506      0.004011         0.020885        0.003909   \n",
       "48       0.022621      0.005107         0.026314        0.004324   \n",
       "49       0.017056      0.005349         0.016095        0.006359   \n",
       "50       0.011559      0.003749         0.015217        0.005986   \n",
       "51       0.020014      0.005509         0.015307        0.003074   \n",
       "52       0.018727      0.004234         0.023950        0.004688   \n",
       "53       0.018922      0.002947         0.017237        0.003748   \n",
       "54       0.018960      0.004214         0.021511        0.003252   \n",
       "55       0.021237      0.005136         0.017230        0.004357   \n",
       "56       0.017987      0.003405         0.023696        0.002710   \n",
       "57       0.018260      0.003811         0.015914        0.002669   \n",
       "58       0.017800      0.002890         0.023520        0.002896   \n",
       "59       0.019445      0.002914         0.014546        0.001643   \n",
       "\n",
       "   param_n_neighbors param_weights  \\\n",
       "0                  1       uniform   \n",
       "1                  1      distance   \n",
       "2                  2       uniform   \n",
       "3                  2      distance   \n",
       "4                  3       uniform   \n",
       "5                  3      distance   \n",
       "6                  4       uniform   \n",
       "7                  4      distance   \n",
       "8                  5       uniform   \n",
       "9                  5      distance   \n",
       "10                 6       uniform   \n",
       "11                 6      distance   \n",
       "12                 7       uniform   \n",
       "13                 7      distance   \n",
       "14                 8       uniform   \n",
       "15                 8      distance   \n",
       "16                 9       uniform   \n",
       "17                 9      distance   \n",
       "18                10       uniform   \n",
       "19                10      distance   \n",
       "20                11       uniform   \n",
       "21                11      distance   \n",
       "22                12       uniform   \n",
       "23                12      distance   \n",
       "24                13       uniform   \n",
       "25                13      distance   \n",
       "26                14       uniform   \n",
       "27                14      distance   \n",
       "28                15       uniform   \n",
       "29                15      distance   \n",
       "30                16       uniform   \n",
       "31                16      distance   \n",
       "32                17       uniform   \n",
       "33                17      distance   \n",
       "34                18       uniform   \n",
       "35                18      distance   \n",
       "36                19       uniform   \n",
       "37                19      distance   \n",
       "38                20       uniform   \n",
       "39                20      distance   \n",
       "40                21       uniform   \n",
       "41                21      distance   \n",
       "42                22       uniform   \n",
       "43                22      distance   \n",
       "44                23       uniform   \n",
       "45                23      distance   \n",
       "46                24       uniform   \n",
       "47                24      distance   \n",
       "48                25       uniform   \n",
       "49                25      distance   \n",
       "50                26       uniform   \n",
       "51                26      distance   \n",
       "52                27       uniform   \n",
       "53                27      distance   \n",
       "54                28       uniform   \n",
       "55                28      distance   \n",
       "56                29       uniform   \n",
       "57                29      distance   \n",
       "58                30       uniform   \n",
       "59                30      distance   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "0     {'n_neighbors': 1, 'weights': 'uniform'}           0.311111   \n",
       "1    {'n_neighbors': 1, 'weights': 'distance'}           0.311111   \n",
       "2     {'n_neighbors': 2, 'weights': 'uniform'}           0.311111   \n",
       "3    {'n_neighbors': 2, 'weights': 'distance'}           0.355556   \n",
       "4     {'n_neighbors': 3, 'weights': 'uniform'}           0.333333   \n",
       "5    {'n_neighbors': 3, 'weights': 'distance'}           0.377778   \n",
       "6     {'n_neighbors': 4, 'weights': 'uniform'}           0.311111   \n",
       "7    {'n_neighbors': 4, 'weights': 'distance'}           0.333333   \n",
       "8     {'n_neighbors': 5, 'weights': 'uniform'}           0.355556   \n",
       "9    {'n_neighbors': 5, 'weights': 'distance'}           0.355556   \n",
       "10    {'n_neighbors': 6, 'weights': 'uniform'}           0.377778   \n",
       "11   {'n_neighbors': 6, 'weights': 'distance'}           0.311111   \n",
       "12    {'n_neighbors': 7, 'weights': 'uniform'}           0.377778   \n",
       "13   {'n_neighbors': 7, 'weights': 'distance'}           0.400000   \n",
       "14    {'n_neighbors': 8, 'weights': 'uniform'}           0.377778   \n",
       "15   {'n_neighbors': 8, 'weights': 'distance'}           0.355556   \n",
       "16    {'n_neighbors': 9, 'weights': 'uniform'}           0.377778   \n",
       "17   {'n_neighbors': 9, 'weights': 'distance'}           0.422222   \n",
       "18   {'n_neighbors': 10, 'weights': 'uniform'}           0.377778   \n",
       "19  {'n_neighbors': 10, 'weights': 'distance'}           0.422222   \n",
       "20   {'n_neighbors': 11, 'weights': 'uniform'}           0.355556   \n",
       "21  {'n_neighbors': 11, 'weights': 'distance'}           0.400000   \n",
       "22   {'n_neighbors': 12, 'weights': 'uniform'}           0.355556   \n",
       "23  {'n_neighbors': 12, 'weights': 'distance'}           0.377778   \n",
       "24   {'n_neighbors': 13, 'weights': 'uniform'}           0.355556   \n",
       "25  {'n_neighbors': 13, 'weights': 'distance'}           0.377778   \n",
       "26   {'n_neighbors': 14, 'weights': 'uniform'}           0.400000   \n",
       "27  {'n_neighbors': 14, 'weights': 'distance'}           0.400000   \n",
       "28   {'n_neighbors': 15, 'weights': 'uniform'}           0.333333   \n",
       "29  {'n_neighbors': 15, 'weights': 'distance'}           0.333333   \n",
       "30   {'n_neighbors': 16, 'weights': 'uniform'}           0.333333   \n",
       "31  {'n_neighbors': 16, 'weights': 'distance'}           0.333333   \n",
       "32   {'n_neighbors': 17, 'weights': 'uniform'}           0.311111   \n",
       "33  {'n_neighbors': 17, 'weights': 'distance'}           0.355556   \n",
       "34   {'n_neighbors': 18, 'weights': 'uniform'}           0.377778   \n",
       "35  {'n_neighbors': 18, 'weights': 'distance'}           0.377778   \n",
       "36   {'n_neighbors': 19, 'weights': 'uniform'}           0.377778   \n",
       "37  {'n_neighbors': 19, 'weights': 'distance'}           0.377778   \n",
       "38   {'n_neighbors': 20, 'weights': 'uniform'}           0.333333   \n",
       "39  {'n_neighbors': 20, 'weights': 'distance'}           0.377778   \n",
       "40   {'n_neighbors': 21, 'weights': 'uniform'}           0.355556   \n",
       "41  {'n_neighbors': 21, 'weights': 'distance'}           0.377778   \n",
       "42   {'n_neighbors': 22, 'weights': 'uniform'}           0.333333   \n",
       "43  {'n_neighbors': 22, 'weights': 'distance'}           0.377778   \n",
       "44   {'n_neighbors': 23, 'weights': 'uniform'}           0.355556   \n",
       "45  {'n_neighbors': 23, 'weights': 'distance'}           0.377778   \n",
       "46   {'n_neighbors': 24, 'weights': 'uniform'}           0.355556   \n",
       "47  {'n_neighbors': 24, 'weights': 'distance'}           0.377778   \n",
       "48   {'n_neighbors': 25, 'weights': 'uniform'}           0.355556   \n",
       "49  {'n_neighbors': 25, 'weights': 'distance'}           0.377778   \n",
       "50   {'n_neighbors': 26, 'weights': 'uniform'}           0.355556   \n",
       "51  {'n_neighbors': 26, 'weights': 'distance'}           0.377778   \n",
       "52   {'n_neighbors': 27, 'weights': 'uniform'}           0.333333   \n",
       "53  {'n_neighbors': 27, 'weights': 'distance'}           0.377778   \n",
       "54   {'n_neighbors': 28, 'weights': 'uniform'}           0.333333   \n",
       "55  {'n_neighbors': 28, 'weights': 'distance'}           0.355556   \n",
       "56   {'n_neighbors': 29, 'weights': 'uniform'}           0.400000   \n",
       "57  {'n_neighbors': 29, 'weights': 'distance'}           0.355556   \n",
       "58   {'n_neighbors': 30, 'weights': 'uniform'}           0.333333   \n",
       "59  {'n_neighbors': 30, 'weights': 'distance'}           0.355556   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.409091           0.522727           0.340909   \n",
       "1            0.409091           0.522727           0.340909   \n",
       "2            0.272727           0.386364           0.318182   \n",
       "3            0.363636           0.431818           0.340909   \n",
       "4            0.340909           0.386364           0.272727   \n",
       "5            0.409091           0.363636           0.318182   \n",
       "6            0.272727           0.477273           0.363636   \n",
       "7            0.340909           0.454545           0.363636   \n",
       "8            0.295455           0.477273           0.272727   \n",
       "9            0.340909           0.454545           0.386364   \n",
       "10           0.295455           0.340909           0.272727   \n",
       "11           0.363636           0.386364           0.363636   \n",
       "12           0.386364           0.500000           0.227273   \n",
       "13           0.454545           0.477273           0.295455   \n",
       "14           0.318182           0.454545           0.272727   \n",
       "15           0.363636           0.454545           0.318182   \n",
       "16           0.318182           0.477273           0.250000   \n",
       "17           0.363636           0.477273           0.318182   \n",
       "18           0.409091           0.386364           0.340909   \n",
       "19           0.409091           0.409091           0.340909   \n",
       "20           0.318182           0.386364           0.250000   \n",
       "21           0.386364           0.386364           0.340909   \n",
       "22           0.363636           0.409091           0.318182   \n",
       "23           0.386364           0.409091           0.386364   \n",
       "24           0.386364           0.409091           0.318182   \n",
       "25           0.409091           0.409091           0.363636   \n",
       "26           0.386364           0.386364           0.318182   \n",
       "27           0.454545           0.409091           0.363636   \n",
       "28           0.386364           0.340909           0.318182   \n",
       "29           0.409091           0.363636           0.386364   \n",
       "30           0.386364           0.409091           0.340909   \n",
       "31           0.454545           0.454545           0.386364   \n",
       "32           0.386364           0.409091           0.318182   \n",
       "33           0.454545           0.409091           0.340909   \n",
       "34           0.386364           0.431818           0.318182   \n",
       "35           0.454545           0.386364           0.363636   \n",
       "36           0.386364           0.454545           0.340909   \n",
       "37           0.454545           0.431818           0.363636   \n",
       "38           0.386364           0.454545           0.318182   \n",
       "39           0.454545           0.431818           0.363636   \n",
       "40           0.386364           0.454545           0.318182   \n",
       "41           0.454545           0.454545           0.340909   \n",
       "42           0.409091           0.386364           0.318182   \n",
       "43           0.454545           0.454545           0.340909   \n",
       "44           0.409091           0.431818           0.340909   \n",
       "45           0.454545           0.454545           0.340909   \n",
       "46           0.386364           0.500000           0.340909   \n",
       "47           0.431818           0.454545           0.363636   \n",
       "48           0.386364           0.454545           0.340909   \n",
       "49           0.454545           0.454545           0.386364   \n",
       "50           0.386364           0.454545           0.340909   \n",
       "51           0.454545           0.454545           0.409091   \n",
       "52           0.409091           0.454545           0.340909   \n",
       "53           0.431818           0.409091           0.386364   \n",
       "54           0.386364           0.431818           0.340909   \n",
       "55           0.431818           0.454545           0.363636   \n",
       "56           0.386364           0.477273           0.318182   \n",
       "57           0.431818           0.454545           0.386364   \n",
       "58           0.363636           0.386364           0.340909   \n",
       "59           0.431818           0.386364           0.386364   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.295455           0.386364           0.340909   \n",
       "1            0.295455           0.386364           0.340909   \n",
       "2            0.272727           0.318182           0.295455   \n",
       "3            0.272727           0.340909           0.272727   \n",
       "4            0.318182           0.363636           0.250000   \n",
       "5            0.318182           0.409091           0.340909   \n",
       "6            0.295455           0.409091           0.295455   \n",
       "7            0.272727           0.386364           0.318182   \n",
       "8            0.318182           0.363636           0.340909   \n",
       "9            0.318182           0.340909           0.340909   \n",
       "10           0.295455           0.431818           0.318182   \n",
       "11           0.272727           0.363636           0.295455   \n",
       "12           0.295455           0.454545           0.295455   \n",
       "13           0.295455           0.409091           0.340909   \n",
       "14           0.318182           0.431818           0.250000   \n",
       "15           0.318182           0.409091           0.295455   \n",
       "16           0.318182           0.500000           0.250000   \n",
       "17           0.318182           0.454545           0.340909   \n",
       "18           0.295455           0.477273           0.272727   \n",
       "19           0.318182           0.454545           0.295455   \n",
       "20           0.363636           0.454545           0.318182   \n",
       "21           0.318182           0.454545           0.340909   \n",
       "22           0.295455           0.500000           0.340909   \n",
       "23           0.340909           0.477273           0.363636   \n",
       "24           0.340909           0.522727           0.409091   \n",
       "25           0.340909           0.500000           0.386364   \n",
       "26           0.386364           0.431818           0.386364   \n",
       "27           0.386364           0.477273           0.363636   \n",
       "28           0.431818           0.431818           0.363636   \n",
       "29           0.409091           0.409091           0.386364   \n",
       "30           0.431818           0.454545           0.363636   \n",
       "31           0.386364           0.431818           0.386364   \n",
       "32           0.386364           0.431818           0.386364   \n",
       "33           0.340909           0.477273           0.318182   \n",
       "34           0.340909           0.363636           0.363636   \n",
       "35           0.318182           0.431818           0.318182   \n",
       "36           0.363636           0.409091           0.363636   \n",
       "37           0.363636           0.454545           0.295455   \n",
       "38           0.363636           0.409091           0.386364   \n",
       "39           0.363636           0.431818           0.340909   \n",
       "40           0.363636           0.431818           0.363636   \n",
       "41           0.386364           0.431818           0.363636   \n",
       "42           0.409091           0.454545           0.340909   \n",
       "43           0.386364           0.431818           0.340909   \n",
       "44           0.431818           0.363636           0.340909   \n",
       "45           0.386364           0.409091           0.340909   \n",
       "46           0.386364           0.409091           0.340909   \n",
       "47           0.363636           0.431818           0.340909   \n",
       "48           0.409091           0.409091           0.386364   \n",
       "49           0.386364           0.454545           0.363636   \n",
       "50           0.409091           0.431818           0.386364   \n",
       "51           0.363636           0.454545           0.340909   \n",
       "52           0.386364           0.409091           0.386364   \n",
       "53           0.386364           0.454545           0.386364   \n",
       "54           0.409091           0.409091           0.386364   \n",
       "55           0.363636           0.454545           0.340909   \n",
       "56           0.409091           0.409091           0.363636   \n",
       "57           0.386364           0.431818           0.340909   \n",
       "58           0.409091           0.409091           0.431818   \n",
       "59           0.409091           0.431818           0.340909   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.363636           0.318182           0.409091         0.369747   \n",
       "1            0.363636           0.318182           0.409091         0.369747   \n",
       "2            0.295455           0.272727           0.204545         0.294747   \n",
       "3            0.295455           0.272727           0.318182         0.326465   \n",
       "4            0.295455           0.250000           0.318182         0.312879   \n",
       "5            0.340909           0.227273           0.340909         0.344596   \n",
       "6            0.386364           0.340909           0.250000         0.340202   \n",
       "7            0.386364           0.295455           0.318182         0.346970   \n",
       "8            0.431818           0.340909           0.295455         0.349192   \n",
       "9            0.363636           0.272727           0.318182         0.349192   \n",
       "10           0.386364           0.318182           0.295455         0.333232   \n",
       "11           0.295455           0.295455           0.318182         0.326566   \n",
       "12           0.454545           0.340909           0.318182         0.365051   \n",
       "13           0.363636           0.318182           0.386364         0.374091   \n",
       "14           0.363636           0.363636           0.409091         0.355960   \n",
       "15           0.295455           0.363636           0.409091         0.358283   \n",
       "16           0.386364           0.363636           0.318182         0.355960   \n",
       "17           0.340909           0.386364           0.386364         0.380859   \n",
       "18           0.409091           0.386364           0.318182         0.367323   \n",
       "19           0.386364           0.409091           0.363636         0.380859   \n",
       "20           0.454545           0.386364           0.363636         0.365101   \n",
       "21           0.409091           0.386364           0.340909         0.376364   \n",
       "22           0.386364           0.363636           0.318182         0.365101   \n",
       "23           0.363636           0.363636           0.386364         0.385505   \n",
       "24           0.431818           0.295455           0.340909         0.381010   \n",
       "25           0.386364           0.295455           0.363636         0.383232   \n",
       "26           0.409091           0.340909           0.386364         0.383182   \n",
       "27           0.363636           0.340909           0.386364         0.394545   \n",
       "28           0.431818           0.363636           0.386364         0.378788   \n",
       "29           0.386364           0.363636           0.431818         0.387879   \n",
       "30           0.431818           0.318182           0.363636         0.383333   \n",
       "31           0.363636           0.340909           0.409091         0.394697   \n",
       "32           0.409091           0.363636           0.318182         0.372020   \n",
       "33           0.363636           0.363636           0.363636         0.378737   \n",
       "34           0.386364           0.340909           0.363636         0.367323   \n",
       "35           0.386364           0.318182           0.363636         0.371869   \n",
       "36           0.409091           0.295455           0.340909         0.374141   \n",
       "37           0.386364           0.318182           0.340909         0.378687   \n",
       "38           0.386364           0.340909           0.386364         0.376515   \n",
       "39           0.386364           0.386364           0.363636         0.390051   \n",
       "40           0.363636           0.340909           0.340909         0.371919   \n",
       "41           0.363636           0.318182           0.386364         0.387778   \n",
       "42           0.363636           0.363636           0.386364         0.376515   \n",
       "43           0.386364           0.363636           0.386364         0.392323   \n",
       "44           0.386364           0.318182           0.363636         0.374192   \n",
       "45           0.386364           0.363636           0.318182         0.383232   \n",
       "46           0.386364           0.318182           0.363636         0.378737   \n",
       "47           0.363636           0.318182           0.340909         0.378687   \n",
       "48           0.409091           0.340909           0.340909         0.383283   \n",
       "49           0.386364           0.318182           0.340909         0.392323   \n",
       "50           0.386364           0.340909           0.409091         0.390101   \n",
       "51           0.386364           0.295455           0.340909         0.387778   \n",
       "52           0.386364           0.386364           0.386364         0.387879   \n",
       "53           0.386364           0.363636           0.340909         0.392323   \n",
       "54           0.409091           0.363636           0.363636         0.383333   \n",
       "55           0.363636           0.386364           0.340909         0.385556   \n",
       "56           0.386364           0.409091           0.363636         0.392273   \n",
       "57           0.340909           0.431818           0.340909         0.390101   \n",
       "58           0.409091           0.363636           0.363636         0.381061   \n",
       "59           0.363636           0.431818           0.340909         0.387828   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.063318               41  \n",
       "1         0.063318               41  \n",
       "2         0.043991               60  \n",
       "3         0.048413               58  \n",
       "4         0.043658               59  \n",
       "5         0.049984               54  \n",
       "6         0.066147               55  \n",
       "7         0.050000               53  \n",
       "8         0.060168               51  \n",
       "9         0.045504               51  \n",
       "10        0.047938               56  \n",
       "11        0.037162               57  \n",
       "12        0.081422               47  \n",
       "13        0.059891               37  \n",
       "14        0.063166               49  \n",
       "15        0.050602               48  \n",
       "16        0.079787               49  \n",
       "17        0.052766               26  \n",
       "18        0.057999               43  \n",
       "19        0.047620               25  \n",
       "20        0.058865               46  \n",
       "21        0.038985               34  \n",
       "22        0.055244               45  \n",
       "23        0.035303               16  \n",
       "24        0.062771               24  \n",
       "25        0.050285               20  \n",
       "26        0.030630               22  \n",
       "27        0.040696                2  \n",
       "28        0.040230               27  \n",
       "29        0.027273               10  \n",
       "30        0.044459               18  \n",
       "31        0.040719                1  \n",
       "32        0.040643               38  \n",
       "33        0.049120               28  \n",
       "34        0.029741               44  \n",
       "35        0.044347               40  \n",
       "36        0.042061               36  \n",
       "37        0.051827               30  \n",
       "38        0.037735               33  \n",
       "39        0.035120                9  \n",
       "40        0.039885               39  \n",
       "41        0.043778               13  \n",
       "42        0.039079               32  \n",
       "43        0.039662                3  \n",
       "44        0.037324               35  \n",
       "45        0.043689               20  \n",
       "46        0.048057               29  \n",
       "47        0.043123               30  \n",
       "48        0.036402               19  \n",
       "49        0.045712                3  \n",
       "50        0.035622                7  \n",
       "51        0.052373               13  \n",
       "52        0.032461               10  \n",
       "53        0.030875                3  \n",
       "54        0.030717               17  \n",
       "55        0.042412               15  \n",
       "56        0.039157                6  \n",
       "57        0.042255                8  \n",
       "58        0.031245               23  \n",
       "59        0.035059               12  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál habrá sido el mejor modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=16, weights='distance')\n",
      "0.39469696969696966\n",
      "{'n_neighbors': 16, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLEGÓ EL MOMENTO DE LA VERDAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos los mejores hiperparámetros para estimar las predicciones sobre los datos de test y evaluar cómo generaliza nuestro modelo ante datos con los que no fue entrenado y que no fueron usados para la búsqueda de hiperparámetros.\n",
    "\n",
    "Para ello, podemos usar el atajo que tiene GridSeachCV: usando el método predict sobre objeto grid (que ya está entrenado con todos los datos de train y con la mejor combinación de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos importar de sklearn, classification_report que nos va a brindar un reporte completo de las principales métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.15      0.19        20\n",
      "           2       0.23      0.14      0.17        22\n",
      "           3       0.34      0.55      0.42        38\n",
      "           4       0.56      0.45      0.50        31\n",
      "\n",
      "    accuracy                           0.37       111\n",
      "   macro avg       0.35      0.32      0.32       111\n",
      "weighted avg       0.37      0.37      0.35       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora cómo se ve la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4 12  1]\n",
      " [ 1  3 16  2]\n",
      " [ 3  6 21  8]\n",
      " [ 4  0 13 14]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred_grid)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAMOS CON REGRESIÓN LOGÍSTICA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos todo en base al algoritmo de KNN de arriba. \n",
    "# Debemos cambiar el nombre de las variables para que un modelo no pise al otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'C': [1, 10, 100, 1000],\n",
    "     'penalty': ['l1', 'l2',],\n",
    "     'solver': ['saga']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=StratifiedKFold(n_splits=10, random_state=19, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LR, params, cv=folds, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=19, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['saga']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_penalty', 'param_solver', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069690</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.392273</td>\n",
       "      <td>0.041712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047305</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.090807</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059369</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097415</td>\n",
       "      <td>0.015423</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 100, 'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.087443</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.128254</td>\n",
       "      <td>0.015965</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.085043</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.069690      0.005757         0.004755        0.001343       1   \n",
       "1       0.047305      0.004039         0.004592        0.001085       1   \n",
       "2       0.090807      0.009598         0.006141        0.001728      10   \n",
       "3       0.059369      0.003815         0.005321        0.000465      10   \n",
       "4       0.097415      0.015423         0.005953        0.000747     100   \n",
       "5       0.087443      0.014531         0.008308        0.001041     100   \n",
       "6       0.128254      0.015965         0.008291        0.001245    1000   \n",
       "7       0.085043      0.007435         0.008232        0.002206    1000   \n",
       "\n",
       "  param_penalty param_solver                                          params  \\\n",
       "0            l1         saga     {'C': 1, 'penalty': 'l1', 'solver': 'saga'}   \n",
       "1            l2         saga     {'C': 1, 'penalty': 'l2', 'solver': 'saga'}   \n",
       "2            l1         saga    {'C': 10, 'penalty': 'l1', 'solver': 'saga'}   \n",
       "3            l2         saga    {'C': 10, 'penalty': 'l2', 'solver': 'saga'}   \n",
       "4            l1         saga   {'C': 100, 'penalty': 'l1', 'solver': 'saga'}   \n",
       "5            l2         saga   {'C': 100, 'penalty': 'l2', 'solver': 'saga'}   \n",
       "6            l1         saga  {'C': 1000, 'penalty': 'l1', 'solver': 'saga'}   \n",
       "7            l2         saga  {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  ...  split3_test_score  \\\n",
       "0                0.4           0.409091  ...           0.340909   \n",
       "1                0.4           0.409091  ...           0.318182   \n",
       "2                0.4           0.409091  ...           0.318182   \n",
       "3                0.4           0.409091  ...           0.318182   \n",
       "4                0.4           0.409091  ...           0.318182   \n",
       "5                0.4           0.409091  ...           0.318182   \n",
       "6                0.4           0.409091  ...           0.318182   \n",
       "7                0.4           0.409091  ...           0.318182   \n",
       "\n",
       "   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0           0.318182           0.409091           0.409091           0.363636   \n",
       "1           0.318182           0.386364           0.363636           0.386364   \n",
       "2           0.318182           0.386364           0.363636           0.386364   \n",
       "3           0.318182           0.386364           0.363636           0.386364   \n",
       "4           0.318182           0.386364           0.363636           0.386364   \n",
       "5           0.318182           0.386364           0.363636           0.386364   \n",
       "6           0.318182           0.386364           0.363636           0.386364   \n",
       "7           0.318182           0.386364           0.363636           0.386364   \n",
       "\n",
       "   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.409091           0.386364         0.392273        0.041712   \n",
       "1           0.431818           0.386364         0.387727        0.045638   \n",
       "2           0.431818           0.386364         0.387727        0.045638   \n",
       "3           0.431818           0.386364         0.387727        0.045638   \n",
       "4           0.431818           0.386364         0.387727        0.045638   \n",
       "5           0.431818           0.386364         0.387727        0.045638   \n",
       "6           0.431818           0.386364         0.387727        0.045638   \n",
       "7           0.431818           0.386364         0.387727        0.045638   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                2  \n",
       "3                2  \n",
       "4                2  \n",
       "5                2  \n",
       "6                2  \n",
       "7                2  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3922727272727272"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l1', 'solver': 'saga'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.32      0.84      0.47        38\n",
      "           4       0.33      0.03      0.06        31\n",
      "\n",
      "    accuracy                           0.30       111\n",
      "   macro avg       0.16      0.22      0.13       111\n",
      "weighted avg       0.20      0.30      0.18       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4 16  0]\n",
      " [ 1  0 21  0]\n",
      " [ 2  2 32  2]\n",
      " [ 0  0 30  1]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred_grid)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE - BAYESSSSSSSSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '4', '4', '1', '4', '4', '3', '4', '4', '3', '2', '4', '4',\n",
       "       '3', '4', '4', '3', '2', '4', '3', '2', '3', '1', '4', '3', '3',\n",
       "       '3', '3', '4', '4', '4', '3', '4', '4', '4', '4', '4', '3', '4',\n",
       "       '1', '4', '1', '1', '3', '1', '3', '3', '4', '3', '4', '3', '4',\n",
       "       '2', '4', '4', '4', '4', '2', '4', '4', '3', '3', '3', '3', '4',\n",
       "       '2', '4', '2', '4', '4', '1', '4', '3', '4', '4', '4', '4', '4',\n",
       "       '2', '3', '3', '4', '4', '3', '3', '3', '2', '2', '4', '4', '4',\n",
       "       '4', '4', '1', '2', '2', '4', '3', '1', '4', '3', '3', '4', '4',\n",
       "       '4', '4', '3', '4', '4', '4', '3'], dtype='<U1')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test, y_pred), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[ 4  4  7  5]\n",
      " [ 1  1 13  7]\n",
      " [ 2  7  4 25]\n",
      " [ 2  1  8 20]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los valores de la diagonal principal (4,1,4,20) son los valores correctamente predichos\n",
    "# El resto (aquellos que no están sobre la diagonal principal) son los errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
